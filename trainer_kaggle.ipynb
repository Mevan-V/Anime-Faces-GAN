{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T13:29:06.438710Z",
     "iopub.status.busy": "2025-08-29T13:29:06.438465Z",
     "iopub.status.idle": "2025-08-29T13:29:13.476608Z",
     "shell.execute_reply": "2025-08-29T13:29:13.475808Z",
     "shell.execute_reply.started": "2025-08-29T13:29:06.438688Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os, datetime, shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T13:29:13.477694Z",
     "iopub.status.busy": "2025-08-29T13:29:13.477330Z",
     "iopub.status.idle": "2025-08-29T13:29:13.695993Z",
     "shell.execute_reply": "2025-08-29T13:29:13.695207Z",
     "shell.execute_reply.started": "2025-08-29T13:29:13.477674Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Check Device Usage ---\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "isCUDA = True if device == torch.device('cuda') else False\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# --- Device Configuration ---\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\" # Removes pytorch memory allocation problem\n",
    "example = torch.randn(1).cuda() if isCUDA else 0 # Triggers CUDA context initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T13:29:13.698021Z",
     "iopub.status.busy": "2025-08-29T13:29:13.697824Z",
     "iopub.status.idle": "2025-08-29T13:29:13.703020Z",
     "shell.execute_reply": "2025-08-29T13:29:13.702308Z",
     "shell.execute_reply.started": "2025-08-29T13:29:13.698005Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/kaggle/input/animefacedataset/images\"\n",
    "\n",
    "# Same noise to see the changes over epochs\n",
    "valid_plot_noise = torch.randn(3, 5, 1, 100, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model weights save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T13:29:13.703905Z",
     "iopub.status.busy": "2025-08-29T13:29:13.703685Z",
     "iopub.status.idle": "2025-08-29T13:29:13.718617Z",
     "shell.execute_reply": "2025-08-29T13:29:13.717907Z",
     "shell.execute_reply.started": "2025-08-29T13:29:13.703888Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Model weights save file for both generator and critic\n",
    "model_folder_path = \"./model_save_files\"\n",
    "\n",
    "# Remove the folder if exists to start new iteration\n",
    "shutil.rmtree(model_folder_path, ignore_errors=True)\n",
    "\n",
    "# Create the folder\n",
    "os.makedirs(model_folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T13:29:13.719625Z",
     "iopub.status.busy": "2025-08-29T13:29:13.719364Z",
     "iopub.status.idle": "2025-08-29T13:29:13.732940Z",
     "shell.execute_reply": "2025-08-29T13:29:13.732272Z",
     "shell.execute_reply.started": "2025-08-29T13:29:13.719604Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0002\n",
    "num_epochs = 40\n",
    "betas = (0.0, 0.9) # Standard GAN betas\n",
    "\n",
    "num_workers = 4 if isCUDA else 0\n",
    "persistent_workers = True\n",
    "batch_size = 128\n",
    "\n",
    "latent_dim = 100 # Higher value = Higher diversity of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T13:29:13.733863Z",
     "iopub.status.busy": "2025-08-29T13:29:13.733621Z",
     "iopub.status.idle": "2025-08-29T13:29:13.748267Z",
     "shell.execute_reply": "2025-08-29T13:29:13.747664Z",
     "shell.execute_reply.started": "2025-08-29T13:29:13.733842Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom dataset\n",
    "class AnimeDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data_dir = data_dir\n",
    "        self.images = os.listdir(self.data_dir) # All images inside dataset\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.data_dir, self.images[idx])\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        # Return standard type of output (input, label) but label not required for WGANs\n",
    "        return img, torch.tensor([1.0], dtype=torch.float32)\n",
    "\n",
    "class PixelNorm(nn.Module):\n",
    "    '''\n",
    "    PixelNorm normalizes over channels which provides stability \n",
    "    over BatchNorm which relies on other images in the batch for \n",
    "    normalization.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Normalize across channels\n",
    "        return x / torch.sqrt(torch.mean(x**2, dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "# Current time (in H:M:S format)\n",
    "def now():\n",
    "    # Change the timezone referred to the UTC\n",
    "    ist_timezone = datetime.timezone(datetime.timedelta(hours=5, minutes=30))\n",
    "    return datetime.datetime.now().astimezone(ist_timezone).strftime('%H:%M:%S')\n",
    "\n",
    "\n",
    "# Plotting for visual validation\n",
    "def valid_plot(model, epoch=None, rows=3, cols=5, latent_dim=100):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Initialize subplots\n",
    "        _, axs = plt.subplots(rows, cols, figsize=((10 / 3) * cols, rows*3))\n",
    "\n",
    "        # Display the epoch number if exists\n",
    "        if epoch:\n",
    "            plt.suptitle(f\"Epoch: {epoch}\")\n",
    "            \n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "\n",
    "                # Generate the image and denormalize\n",
    "                noise = valid_plot_noise[i][j]\n",
    "                image = model(noise)[0].permute(1, 2, 0).to('cpu').detach().numpy()\n",
    "                image = (image + 1) / 2 # Denormalize\n",
    "\n",
    "                # Plot the images subplot wise\n",
    "                axs[i][j].imshow(image)\n",
    "                axs[i][j].get_xaxis().set_visible(False)\n",
    "                axs[i][j].get_yaxis().set_visible(False)\n",
    "        plt.show()\n",
    "\n",
    "# Custom weights initialization\n",
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "\n",
    "        # Initialize to prevent exploding gradients\n",
    "        torch.nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# Custom padding function\n",
    "def zero_pad(x, pad_len=3):\n",
    "\n",
    "    # Make sure it is a string\n",
    "    x = str(x)\n",
    "    x_len = len(x)\n",
    "\n",
    "    # Add zeros until pad_len\n",
    "    for _ in range(pad_len - x_len):\n",
    "        x = \"0\" + x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T13:29:13.749137Z",
     "iopub.status.busy": "2025-08-29T13:29:13.748947Z",
     "iopub.status.idle": "2025-08-29T13:29:14.323007Z",
     "shell.execute_reply": "2025-08-29T13:29:14.322441Z",
     "shell.execute_reply.started": "2025-08-29T13:29:13.749119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mean, std = [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),                 \n",
    "    transforms.ToTensor(),                         \n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# Dataset\n",
    "img_dataset = AnimeDataset(DATA_DIR, transform)\n",
    "\n",
    "# Divide the dataset (numbers)\n",
    "dataset_size = len(img_dataset[0])\n",
    "\n",
    "# Load the images\n",
    "train_loader = DataLoader(img_dataset, batch_size = batch_size, shuffle = True, num_workers = num_workers, pin_memory = True, persistent_workers = persistent_workers)\n",
    "\n",
    "# Logging\n",
    "print(f\"Sizes of Train: {dataset_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T13:29:14.323838Z",
     "iopub.status.busy": "2025-08-29T13:29:14.323663Z",
     "iopub.status.idle": "2025-08-29T13:29:15.686448Z",
     "shell.execute_reply": "2025-08-29T13:29:15.685252Z",
     "shell.execute_reply.started": "2025-08-29T13:29:14.323824Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    # Generate a single image\n",
    "    image = images[0].permute(1, 2, 0).cpu().numpy()\n",
    "    image_min, image_max = image.min().item(), image.max().item()\n",
    "    image = (image + 1) / 2 # Denormalize\n",
    "    image_min2, image_max2 = image.min().item(), image.max().item()\n",
    "\n",
    "    # Plot the image\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "    # Test max and min values of image before and after\n",
    "    print(f\"Min: {image_min}, Max: {image_max}\")\n",
    "    print(f\"Min: {image_min2}, Max: {image_max2}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T13:29:15.690701Z",
     "iopub.status.busy": "2025-08-29T13:29:15.689784Z",
     "iopub.status.idle": "2025-08-29T13:29:15.700392Z",
     "shell.execute_reply": "2025-08-29T13:29:15.699648Z",
     "shell.execute_reply.started": "2025-08-29T13:29:15.690655Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convA = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1),      # [B, 64, 32, 32]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 4, 2, 1),    # [B, 128, 16, 16]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 4, 2, 1),   # [B, 256, 8, 8]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(256, 512, 4, 2, 1),   # [B, 512, 4, 4]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(512, 1024, 4, 2, 1),  # [B, 1024, 2, 2]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        # Two different paths to extract different features\n",
    "        self.convB = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),      # [B, 64, 64, 64]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2),             # [B, 64, 32, 32]\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, 1, 1),    # [B, 128, 32, 32]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2),             # [B, 256, 16, 16]\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, 1, 1),   # [B, 256, 16, 16]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2),             # [B, 256, 8, 8]\n",
    "            \n",
    "            nn.Conv2d(256, 512, 3, 1, 1),   # [B, 512, 8, 8]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2),             # [B, 512, 4, 4]\n",
    "            \n",
    "            nn.Conv2d(512, 1024, 3, 1, 1),  # [B, 1024, 4, 4]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2),             # [B, 1024, 2, 2]\n",
    "            nn.Flatten()                    # [B, 4096]\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(2048*2*2, 1)          # [B, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        xA = self.convA(x)\n",
    "        xB = self.convB(x)\n",
    "        x = torch.cat((xA, xB), dim=1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T13:29:15.701358Z",
     "iopub.status.busy": "2025-08-29T13:29:15.701110Z",
     "iopub.status.idle": "2025-08-29T13:29:15.893913Z",
     "shell.execute_reply": "2025-08-29T13:29:15.893066Z",
     "shell.execute_reply.started": "2025-08-29T13:29:15.701343Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim = 100):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 1024*1*1),  # [B, 1024]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Linear(1024*1*1, 512*4*4),     # [B, 8192]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Unflatten(1, (512, 4, 4))      # [B, 512, 4, 4]\n",
    "        )\n",
    "        self.convA = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False),\n",
    "            nn.Conv2d(512, 256, 3, 1, 1),     # [B, 512, 8, 8] -> [B, 256, 8, 8]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            PixelNorm(),\n",
    "            \n",
    "            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False),\n",
    "            nn.Conv2d(256, 128, 3, 1, 1),     # [B, 256, 16, 16] -> [B, 128, 16, 16]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            PixelNorm(),\n",
    "            \n",
    "            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False),\n",
    "            nn.Conv2d(128, 64, 3, 1, 1),      # [B, 128, 32, 32] -> [B, 64, 32, 32]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            PixelNorm(),\n",
    "            \n",
    "            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False),\n",
    "            nn.Conv2d(64, 32, 3, 1, 1),       # [B, 64, 64, 64] -> [B, 32, 64, 64]     \n",
    "            nn.LeakyReLU(0.2),\n",
    "            PixelNorm()\n",
    "        )\n",
    "        # Two different paths to generate different features\n",
    "        self.convB = nn.Sequential(\n",
    "\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1),   # [B, 256, 8, 8]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            PixelNorm(),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1),   # [B, 128, 16, 16]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            PixelNorm(),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),    # [B, 64, 32, 32]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            PixelNorm(),\n",
    "            \n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1),     # [B, 32, 64, 64]\n",
    "            nn.LeakyReLU(0.2),\n",
    "            PixelNorm()\n",
    "        )\n",
    "        self.convOut = nn.Sequential(\n",
    "            nn.Conv2d(64, 3, 1, 1, 0),               # [B, 3, 64, 64]\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        xA = self.convA(x)\n",
    "        xB = self.convB(x)\n",
    "        x = torch.cat((xA, xB), dim=1)\n",
    "        return self.convOut(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T13:29:15.895188Z",
     "iopub.status.busy": "2025-08-29T13:29:15.894796Z",
     "iopub.status.idle": "2025-08-29T13:29:17.430191Z",
     "shell.execute_reply": "2025-08-29T13:29:17.429474Z",
     "shell.execute_reply.started": "2025-08-29T13:29:15.895163Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gen = Generator().to(device)\n",
    "valid_plot(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T13:29:17.431285Z",
     "iopub.status.busy": "2025-08-29T13:29:17.431001Z",
     "iopub.status.idle": "2025-08-29T13:29:18.117420Z",
     "shell.execute_reply": "2025-08-29T13:29:18.116885Z",
     "shell.execute_reply.started": "2025-08-29T13:29:17.431247Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GAN(nn.Module):\n",
    "    def __init__(self, lr=learning_rate, latent_dim=100):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Create both the model networks\n",
    "        self.G = torch.jit.script(Generator(latent_dim=self.latent_dim))\n",
    "        self.C = torch.jit.script(Critic())\n",
    "\n",
    "        # Define lr separately for each\n",
    "        lr_G = lr * 0.5\n",
    "        lr_C = lr * 0.5\n",
    "\n",
    "        # Optimizers\n",
    "        self.optim_G = torch.optim.Adam(self.G.parameters(), lr=lr_G, betas=betas)\n",
    "        self.optim_C = torch.optim.Adam(self.C.parameters(), lr=lr_C, betas=betas)\n",
    "\n",
    "        # Batch no. counter\n",
    "        self.batch_no_g = 0\n",
    "        self.batch_no_c = 0\n",
    "\n",
    "        # Scalers\n",
    "        self.scaler_G = GradScaler('cuda')\n",
    "        self.scaler_C = GradScaler('cuda')\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.eval()\n",
    "        # Generates the images\n",
    "        return self.G(x)\n",
    "\n",
    "    def epoch_reset(self):\n",
    "        # Resets counters to 0\n",
    "        self.batch_no_g = 0\n",
    "        self.batch_no_c = 0\n",
    "\n",
    "    def batch_nos(self):\n",
    "        # Returns batch no. counters\n",
    "        return self.batch_no_c, self.batch_no_g\n",
    "\n",
    "    def gradient_penalty(self, real, fake, device):\n",
    "        '''\n",
    "        Gradient Penalty function\n",
    "        -> Maintains the Lipschitz constant at 1\n",
    "        -> Stable gradients\n",
    "        -> Reduces vanishing or exploding of gradients\n",
    "        '''\n",
    "        batch_size = real.size(0)\n",
    "        # Calculate gradients in real-fake space using epsilon\n",
    "        epsilon = torch.rand(batch_size, 1, 1, 1, device=device)\n",
    "        mixed = (epsilon * real + (1 - epsilon) * fake).requires_grad_(True)\n",
    "\n",
    "        # Calculate gradients\n",
    "        mixed_scores = self.C(mixed)\n",
    "        grad_outputs = torch.ones_like(mixed_scores)\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=mixed_scores,\n",
    "            inputs=mixed,\n",
    "            grad_outputs=grad_outputs,\n",
    "            create_graph=True,\n",
    "            retain_graph=True\n",
    "        )[0]\n",
    "        gradients = gradients.view(batch_size, -1)\n",
    "\n",
    "        # Calculate penalty\n",
    "        gp = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "        return gp\n",
    "\n",
    "    def critic_loss(self, real, fake, gp, lambda_gp=10):\n",
    "        with autocast('cuda'):\n",
    "            # Get scores of both images\n",
    "            real_score = self.C(real).mean()\n",
    "            fake_score = self.C(fake).mean()\n",
    "\n",
    "        # Log gradient penality, real and fake losses and the gap\n",
    "        if self.batch_no_c % (50 * 5) == 0:\n",
    "            print(f\"Gradient Penality(* \\u03BB): {gp * lambda_gp:8.4f}, Real score: {real_score:8.4f}, Fake Score: {fake_score:8.4f}, Gap: {real_score - fake_score:8.4f}\")\n",
    "\n",
    "        # Return total loss with gradient penalty\n",
    "        return fake_score - real_score + lambda_gp * gp\n",
    "\n",
    "    def generator_loss(self, fake):\n",
    "        with autocast('cuda'):\n",
    "            loss = -self.C(fake).mean()\n",
    "        return loss\n",
    "    \n",
    "    def train_model(self, batch):\n",
    "        self.train()\n",
    "        real_images, _ = batch # No labels required in WGANs\n",
    "        real_images = real_images.to(device)\n",
    "        num_images = len(real_images) # Batch size\n",
    "\n",
    "        # No. of times critic should get trained per batch\n",
    "        n_critic = 5\n",
    "\n",
    "        # --- Critic ---\n",
    "\n",
    "        for _ in range(n_critic):\n",
    "\n",
    "            # Update counter\n",
    "            self.batch_no_c += 1\n",
    "\n",
    "            # Create fake images\n",
    "            noise = torch.randn(num_images, self.latent_dim, dtype=torch.float32).to(device)\n",
    "            fake_images = self.G(noise).detach()\n",
    "\n",
    "            # Calculate gradient penalty and critic loss\n",
    "            gp = self.gradient_penalty(real_images, fake_images, device)\n",
    "            c_loss = self.critic_loss(real_images, fake_images, gp, 10)\n",
    "\n",
    "            # Backward pass\n",
    "            self.optim_C.zero_grad()\n",
    "            self.scaler_C.scale(c_loss).backward()\n",
    "            self.scaler_C.step(self.optim_C)\n",
    "            self.scaler_C.update()\n",
    "\n",
    "        # --- Generator ---\n",
    "\n",
    "        # Update counter\n",
    "        self.batch_no_g += 1\n",
    "\n",
    "        # Create fake images\n",
    "        noise = torch.randn(num_images, self.latent_dim, dtype=torch.float32).to(device)\n",
    "        fake_images = self.G(noise)\n",
    "\n",
    "        # Calculate generator loss\n",
    "        g_loss = self.generator_loss(fake_images)\n",
    "\n",
    "        # Backward pass\n",
    "        self.optim_G.zero_grad()\n",
    "        self.scaler_G.scale(g_loss).backward()\n",
    "        self.scaler_G.step(self.optim_G)\n",
    "        self.scaler_G.update()\n",
    "\n",
    "        # Return losses for logging\n",
    "        return c_loss * n_critic, g_loss # n_critic because it is training for more steps\n",
    "\n",
    "# Initialize the GAN Model\n",
    "model = GAN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-29T13:30:58.575Z",
     "iopub.execute_input": "2025-08-29T13:29:18.118376Z",
     "iopub.status.busy": "2025-08-29T13:29:18.118131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Training started! Time: {now()}\")\n",
    "\n",
    "# Model save file names\n",
    "save_file_name = \"gen_checkpoint_\"\n",
    "critic_file_name = \"crit_checkpoint_\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Initializing losses to 0\n",
    "    c_loss_total, g_loss_total = 0, 0\n",
    "\n",
    "    # Reset model counters\n",
    "    model.epoch_reset()\n",
    "\n",
    "    for batch in train_loader:\n",
    "\n",
    "        # Train model and get losses\n",
    "        c_loss, g_loss = model.train_model(batch)\n",
    "\n",
    "        # Add losses to the total losses\n",
    "        c_loss_total += c_loss\n",
    "        g_loss_total += g_loss\n",
    "\n",
    "    # Get the batch no. counters\n",
    "    batch_no_c, batch_no_g = model.batch_nos()\n",
    "\n",
    "    # Calculate the mean of losses\n",
    "    c_loss_total /= batch_no_c\n",
    "    g_loss_total /= batch_no_g\n",
    "\n",
    "    # Log\n",
    "    print(f\"\\n\\nEpoch: {epoch + 1}, Time: {now()}\")\n",
    "    print(f\"c_loss: {c_loss_total:6.4f}\")\n",
    "    print(f\"g_loss: {g_loss_total:6.4f}\\n\\n\")\n",
    "    valid_plot(model, epoch + 1)\n",
    "\n",
    "    # Save model weights every iteration\n",
    "    save_file_name_epoch = save_file_name + zero_pad(epoch + 1) + \".pth\"\n",
    "    save_loc = os.path.join(model_folder_path, save_file_name_epoch)\n",
    "    torch.save(model.G.state_dict(), save_loc)\n",
    "    \n",
    "    critic_file_name_epoch = critic_file_name + zero_pad(epoch + 1) + \".pth\"\n",
    "    save_loc = os.path.join(model_folder_path, critic_file_name_epoch)\n",
    "    torch.save(model.C.state_dict(), save_loc)\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 379764,
     "sourceId": 737475,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
